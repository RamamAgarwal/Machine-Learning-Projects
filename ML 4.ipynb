{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "* You need to code in this jupyter notebook only.\n",
    "* Download this notebook and import in your jupyter lab.\n",
    "* You need to write a partial code for step 0 to step 8 mentioned with prefix ##\n",
    "* Fill the blanks where it is instructed in comments. \n",
    "* Leave other codes, structure as it is.\n",
    "* Follow all the instructions commented in a cells.\n",
    "\n",
    "\n",
    "\n",
    "**Answer the questions given at the end of this notebook within your report.**\n",
    "\n",
    "**Upload this jupyter notebook after completion with your partial code and the report in one file in PDF format.**\n",
    "\n",
    "**Also upload the resulting image showing all the selected points and boundary line between them after LDA analysis.**\n",
    "\n",
    "**Your file name should be yourname_lab4.pdf. Upload it before the due time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np ## import numpy\n",
    "import cv2 ## import opencv\n",
    "import matplotlib ## import matplotlib\n",
    "import matplotlib.pyplot as plt ## import matplotlib pyplot\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis ## from sklearn import LDA analysis\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "##---------------------------------------------------\n",
    "## Step 0: Install all other dependencies that occur at run time if  any module not found.\n",
    "##---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_of_points = 20  ## Number of points you want select from each strip. Recommended >= 20 \n",
    "\n",
    "img = cv2.imread(\"Indian_Flag.jpg\") ## Read the given image\n",
    "\n",
    "def select_points(img, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    #------------------------------------------\n",
    "    ## step 1: Convert the img from BGR to RGB using cv2 and display it using cv2.imshow\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(img)\n",
    "    ## step 2: Put title of the image\n",
    "    ax.set_title(title)\n",
    "    ##-----------------------------------------\n",
    "    \n",
    "    # Set the cursor style to a plus sign\n",
    "    fig.canvas.manager.set_window_title('Select Points')\n",
    "    cursor = matplotlib.widgets.Cursor(ax, useblit=True, color='red', linewidth=1)\n",
    "    plt.show(block=False)  # Show the image without blocking\n",
    "\n",
    "    k = 0\n",
    "    points = [] ## Create here an empty list to store points \n",
    "\n",
    "    while k < Number_of_points:\n",
    "        xy = plt.ginput(1, timeout=0)  # Non-blocking input\n",
    "        if len(xy) > 0:\n",
    "            col, row = map(int, xy[0])  # Convert to integer\n",
    "            ##-----------------------------------------------\n",
    "            ## Step 3: Collect RGB values at the clicked positions (col, row) and print it.\n",
    "            rgb_val = img[row,col]\n",
    "            print(rgb_val)\n",
    "            ##-----------------------------------------------\n",
    "\n",
    "            k += 1\n",
    "            points.append([row, col, img[row, col]])  # Store RGB values in empty list points.\n",
    "            \n",
    "            # Display colored dot on the image\n",
    "            plt.scatter(col, row, c='black', marker='o', s=10)\n",
    "\n",
    "            # Redraw the image to include the dot\n",
    "            plt.draw()\n",
    "\n",
    "    plt.close()  # Close the window after all points are collected\n",
    "    return points ## Fill this blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[243  85  22]\n",
      "[229  82  31]\n",
      "[254 100  30]\n",
      "[244  90  20]\n",
      "[241  87  17]\n",
      "[208 205 186]\n",
      "[255 104  28]\n",
      "[247  86  18]\n",
      "[245  86  18]\n",
      "[245  81  10]\n",
      "[248  82   8]\n",
      "[235  68   0]\n",
      "[247  72   7]\n",
      "[243  76   6]\n",
      "[241  75  15]\n",
      "[193  87  45]\n",
      "[223  66  21]\n",
      "[246  89  34]\n",
      "[248  87  17]\n",
      "[244  80   9]\n",
      "[217 220 239]\n",
      "[221 221 223]\n",
      "[227 220 227]\n",
      "[255 220 193]\n",
      "[219 222 195]\n",
      "[209 208 222]\n",
      "[214 215 236]\n",
      "[ 89  87 101]\n",
      "[221 217 216]\n",
      "[227 229 241]\n",
      "[217 214 225]\n",
      "[225 225 235]\n",
      "[233 224 241]\n",
      "[217 215 218]\n",
      "[224 218 230]\n",
      "[216 215 231]\n",
      "[228 227 245]\n",
      "[216 217 235]\n",
      "[192 188 205]\n",
      "[210 204 216]\n",
      "[29 93 69]\n",
      "[29 97 72]\n",
      "[33 96 67]\n",
      "[31 91 66]\n",
      "[27 91 65]\n",
      "[23 88 64]\n",
      "[24 90 63]\n",
      "[25 91 64]\n",
      "[32 97 77]\n",
      "[32 96 72]\n",
      "[29 95 68]\n",
      "[26 99 70]\n",
      "[21 87 59]\n",
      "[33 98 74]\n",
      "[31 97 70]\n",
      "[24 82 58]\n",
      "[18 82 56]\n",
      "[23 87 61]\n",
      "[27 98 68]\n",
      "[ 31 103  79]\n"
     ]
    }
   ],
   "source": [
    "##-----------------------------------------------------------------\n",
    "## Step4: fill the blanks for Selected points from saffron strip\n",
    "pts_saffron = select_points(img, \"Select points from saffron strip\")\n",
    "## Step5: fill the blanks for Selected points from white strip)\n",
    "pts_white = select_points(img, \"Select points from white strip\")\n",
    "## Step6: fill the blanks for Selected points from green strip\n",
    "pts_green = select_points(img, \"Select points from green strip\")\n",
    "##-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB values to Lab color space\n",
    "def rgb_to_lab(rgb):\n",
    "    return cv2.cvtColor(np.uint8([[rgb]]), cv2.COLOR_RGB2Lab)[0][0]\n",
    "\n",
    "saffron_lab = np.array([rgb_to_lab(rgb) for _, _, rgb in pts_saffron])\n",
    "white_lab = np.array([rgb_to_lab(rgb) for _, _, rgb in pts_white])\n",
    "green_lab = np.array([rgb_to_lab(rgb) for _, _, rgb in pts_green])\n",
    "\n",
    "## Step7: Extract a* and b* components from Lab color space\n",
    "a_features = np.hstack([saffron_lab[:, 1], white_lab[:, 1], green_lab[:, 1]])\n",
    "b_features = np.hstack([saffron_lab[:, 2], white_lab[:, 2], green_lab[:, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map class labels to numeric values\n",
    "class_mapping = {'Saffron': 0, 'White': 1, 'Green': 2}\n",
    "y = np.array([class_mapping[label] for label in ['Saffron'] * Number_of_points + ['White'] * Number_of_points + ['Green'] * Number_of_points])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(a_features[:Number_of_points], b_features[:Number_of_points], c='b', marker='o', s=50, label='Saffron')\n",
    "plt.scatter(a_features[Number_of_points:2*Number_of_points], b_features[Number_of_points:2*Number_of_points], c='g', marker='^', s=50, label='White')\n",
    "plt.scatter(a_features[2*Number_of_points:], b_features[2*Number_of_points:], c='r', marker='*', s=50, label='Green')\n",
    "plt.legend(['Saffron', 'White', 'Green'], loc='best')\n",
    "plt.xlabel('a* Component (Lab Color Space)')  ## Provide x label\n",
    "plt.ylabel('b* Component (Lab Color Space)') ## Provide y label\n",
    "plt.title('a* vs b* Components in Lab Color Space for Indian Flag Colors') ## Provide title\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "##------------------------------------------------------------\n",
    "# Step 8: Perform LDA analysis using LinearDiscriminantAnalysis() and lda.fit()\n",
    "X = np.vstack([saffron_lab[:, 1:3], white_lab[:, 1:3], green_lab[:, 1:3]])\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X, y)\n",
    "X_lda = lda.transform(X)\n",
    "##-----------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot LDA boundaries\n",
    "plt.figure()\n",
    "plt.scatter(a_features[:Number_of_points], b_features[:Number_of_points], c='b', marker='o', s=50, label='Saffron')\n",
    "plt.scatter(a_features[Number_of_points:2*Number_of_points], b_features[Number_of_points:2*Number_of_points], c='g', marker='^', s=50, label='White')\n",
    "plt.scatter(a_features[2*Number_of_points:], b_features[2*Number_of_points:], c='r', marker='*', s=50, label='Green')\n",
    "\n",
    "plt.xlabel('First LDA Component')  ## Provide x label\n",
    "plt.ylabel('LDA Projection of Indian Flag Colors') ## Provide y label\n",
    "plt.title('LDA boundaries (linear model) for Colors of the Indian Flag')\n",
    "\n",
    "# Plot the decision boundaries\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 100), np.linspace(ylim[0], ylim[1], 100))\n",
    "Z = lda.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contour(xx, yy, Z, colors='k', linewidths=2, linestyles='solid')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report:\n",
    "\n",
    "## Answer the following questions within your report:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\tWhat are the key assumptions underlying LDA, and how do these assumptions influence the model's performance?\n",
    "\n",
    "### 2.\tWhat are the hyperparameters in LDA, and how do they affect the outcome of the model?\n",
    "\n",
    "### 3.\tWhat methods can be used to assess an LDA model's effectiveness in terms of separation of topics and the coherence of generated topics?\n",
    "\n",
    "### 4.\tWhat are some common challenges or limitations associated with LDA, and how can they be addressed or mitigated?\n",
    "\n",
    "### 5. What practical applications does this assignment have in real-world situations, and what benefits does it offer in those specific scenarios?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Some of the key assumptions underlying LDA are:\n",
    "\n",
    "1. Linear Separable classes- LDA assumes that different classes (here, saffron, white, green) can be separated by a linear decision boundary. If classes are not linearly separable, LDA may not perform well.\n",
    "2. Normally Distributed Features (Multivariate Gaussian Distribution)- Each class should have a normal (Gaussian) distribution in feature space. If the data is skewed or non-Gaussian, LDA may fail to properly classify points.\n",
    "3. Equal Covariance Across Classes (Homogeneity of Variance)- LDA assumes that the variance-covariance structure of different classes is the same.\n",
    "4. Independence of Features (No Multicollinearity)- Features should not be highly correlated with each other.\n",
    "\n",
    "Q2: Some of the hyperparameters in LDA are:\n",
    "\n",
    "1. Components (n_components): Retains up to C-1 discriminant axes(C is no. of classes)\n",
    "2. Solver (solver): 'svd' is fast; 'lsqr' and 'eigen' handle varying covariance better.\n",
    "3. Shrinkage (shrinkage): Regularize covariance estimation, prevent overfitting\n",
    "\n",
    "Q3: To evaluate how well LDA separates data, we use these metrics:\n",
    "\n",
    "1. Accuracy, Precision, and Recall - Check classification performance using confusion matrices and F1-score.\n",
    "2. Scatter Plots & Decision Boundaries - Visualizing LDA’s decision regions can help understand separation.\n",
    "3. Explained Variance Ratio - Measures how much variance each component captures.\n",
    "4. Cross-validation - Splitting the dataset into training and testing parts helps validate LDA's generalization ability.\n",
    "\n",
    "Q4: Some of the limitations of LDA are:\n",
    "\n",
    "1. The classes may not be linearly separable. For mitigating this limitation, we can use kernel LDA or SVMs.\n",
    "2.  LDA produces at most C-1 projections i.e., it reduces original features dimensionality to at most C-1 dimensions. Thus, if the classification error after LDA is high and more features are needed, some other method must be employed to provide those additional features.\n",
    "3. Assumption of Normality and Equal Covariance - If data isn’t normally distributed, we can use QDA (Quadratic Discriminant Analysis) instead.\n",
    "\n",
    "Q5: This assignment on LDA has many applications in classification problems, including:\n",
    "\n",
    "1. Image Recognition (Face & Object Detection) - Used in Fisherfaces for face recognition.\n",
    "2. Text & Topic Classification - Used in Natural Language Processing (NLP) to classify news articles or detect spam emails.\n",
    "3. Disease Classification on patients’ data - Classifying diseases as mild, moderate, or severe using various parameters of patient health\n",
    "4. Radar and Signal Processing - Used to separate noise from real signals in radar systems.\n",
    "5. Biometric Authentication - Used in fingerprint and iris recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
